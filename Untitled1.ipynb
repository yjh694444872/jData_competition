{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_train = pd.read_csv('./uid_train.txt',sep='\\t',header=None,names=('uid','label'))\n",
    "voice_train = pd.read_csv('./voice_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str})\n",
    "sms_train = pd.read_csv('./sms_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str})\n",
    "wa_train = pd.read_csv('./wa_train.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_test = pd.read_csv('./voice_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str})\n",
    "sms_test = pd.read_csv('./sms_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str})\n",
    "wa_test = pd.read_csv('./wa_test_b.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_test = pd.DataFrame({'uid':pd.unique(wa_test['uid'])})\n",
    "uid_test.to_csv('./uid_test_b.txt',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice = pd.concat([voice_train,voice_test],axis=0)\n",
    "sms = pd.concat([sms_train,sms_test],axis=0)\n",
    "wa = pd.concat([wa_train,wa_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "voice_opp_num = voice.groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('voice_opp_num_').reset_index()\n",
    "\n",
    "voice_opp_head=voice.groupby(['uid'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('voice_opp_head_').reset_index()\n",
    "\n",
    "voice_opp_len=voice.groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('voice_opp_len_').reset_index().fillna(0)\n",
    "\n",
    "voice_opp_len1 = voice.groupby(['uid'])['opp_len'].agg(['std','max','min','median','mean','sum']).add_prefix('voice_opp_len1_').reset_index()\n",
    "\n",
    "voice_call_type = voice.groupby(['uid','call_type'])['uid'].count().unstack().add_prefix('voice_call_type_').reset_index().fillna(0)\n",
    "\n",
    "voice_in_out = voice.groupby(['uid','in_out'])['uid'].count().unstack().add_prefix('voice_in_out_').reset_index().fillna(0)\n",
    "\n",
    "voice_start_time = voice.groupby(['uid'])['start_time'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('voice_start_time_').reset_index()\n",
    "\n",
    "voice_end_time = voice.groupby(['uid'])['end_time'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('voice_end_time_').reset_index()\n",
    "\n",
    "voice['dura_time'] = voice.end_time.str.slice(2, 8).astype(int) - voice.start_time.str.slice(2, 8).astype(int)\n",
    "\n",
    "voice_dura_time = voice.groupby(['uid'])['dura_time'].agg(['std','max','min','median','mean','sum']).add_prefix('voice_dura_time_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "sms_opp_num = sms.groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('sms_opp_num_').reset_index()\n",
    "\n",
    "sms_opp_head=sms.groupby(['uid'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('sms_opp_head_').reset_index()\n",
    "\n",
    "sms_opp_len=sms.groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('sms_opp_len_').reset_index().fillna(0)\n",
    "\n",
    "sms_start_time = sms.groupby(['uid'])['start_time'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('sms_start_time_').reset_index()\n",
    "\n",
    "\n",
    "sms_in_out = sms.groupby(['uid','in_out'])['uid'].count().unstack().add_prefix('sms_in_out_').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: using a dict on a Series for aggregation\n",
      "is deprecated and will be removed in a future version\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "wa_name = wa.groupby(['uid'])['wa_name'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('wa_name_').reset_index()\n",
    "visit_cnt = wa.groupby(['uid'])['visit_cnt'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_visit_cnt_').reset_index()\n",
    "\n",
    "visit_dura = wa.groupby(['uid'])['visit_dura'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_visit_dura_').reset_index()\n",
    "\n",
    "\n",
    "up_flow = wa.groupby(['uid'])['up_flow'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_up_flow_').reset_index()\n",
    "\n",
    "down_flow = wa.groupby(['uid'])['down_flow'].agg(['std','max','min','median','mean','sum']).add_prefix('wa_down_flow_').reset_index()\n",
    "\n",
    "wa_type = wa.groupby(['uid','wa_type'])['uid'].count().unstack().add_prefix('wa_type_').reset_index().fillna(0)\n",
    "\n",
    "wa_date = wa.groupby(['uid'])['date'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('wa_date_').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = [voice_opp_num,voice_opp_head,voice_opp_len,voice_start_time,voice_end_time,voice_call_type,voice_in_out,sms_opp_num,sms_opp_head,sms_opp_len,sms_in_out,sms_start_time,wa_name,visit_cnt,visit_dura,up_flow,\n",
    "           down_flow,wa_type,wa_date,voice_dura_time,voice_opp_len1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = uid_train\n",
    "for feat in feature:\n",
    "    train_feature=pd.merge(train_feature,feat,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = uid_test\n",
    "for feat in feature:\n",
    "    test_feature=pd.merge(test_feature,feat,how='left',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.to_csv('./train_featureV1.csv',index=None)\n",
    "test_feature.to_csv('./test_featureV1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
